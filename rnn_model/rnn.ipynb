{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/ezshen/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import sklearn as sk\n",
    "\n",
    "WORD_VECTOR_PATH = \"data/wordVectors.txt\"\n",
    "VOCAB_PATH = \"data/vocab.txt\"\n",
    "DATA_PATH = \"data/primary_debates.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(in_file):\n",
    "    df = pd.read_csv(in_file, quotechar='\"', delimiter=\",\")\n",
    "\n",
    "    # filter out bad speakers\n",
    "    df = df[(df.Speaker != 'AUDIENCE') & (df.Speaker != 'OTHER') & (df.Speaker != 'CANDIDATES') & (df.Speaker != 'QUESTION')]\n",
    "    \n",
    "    # split text into sentences\n",
    "    tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "    df = pd.concat([pd.Series(row.Party, tokenizer.tokenize(row.Text)) for _, row in df.iterrows()]).reset_index()\n",
    "    df = df.rename(index=str, columns={'index': 'Text', 0: 'Party'})\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "        if row.Text[-1] == '.': # get rid of periods and make lowercase\n",
    "            row.Text = row.Text.lower()[:-1]\n",
    "        else: \n",
    "            row.Text = row.Text.lower()\n",
    "            \n",
    "        if row.Party == 'Republican': # Democratic = 0, Republican = 1\n",
    "            row.Party = 1 \n",
    "        else: row.Party = 0 \n",
    "\n",
    "    return df.Text.values.astype(str), df.Party.values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = load_and_preprocess_data(DATA_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "468030"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from string import punctuation\n",
    "all_text = ''.join([c for c in x if c not in punctuation])\n",
    "text = all_text.split('\\n')\n",
    "\n",
    "all_text = ' '.join(text)\n",
    "words = all_text.split()\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "468030"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "counts = Counter(words)\n",
    "vocab = sorted(counts, key=counts.get, reverse=True)\n",
    "vocab_to_int = {word: ii for ii, word in enumerate(vocab, 1)}\n",
    "\n",
    "vocab_ints = []\n",
    "for each in text:\n",
    "    vocab_ints.append([vocab_to_int[word] for word in each.split()])\n",
    "len(vocab_ints[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({468030: 1})\n",
      "Zero-length reviews: 0\n",
      "Maximum review length: 468030\n"
     ]
    }
   ],
   "source": [
    "sent_lens = Counter([len(x) for x in vocab_ints])\n",
    "print sent_lens\n",
    "print(\"Zero-length reviews: {}\".format(sent_lens[0]))\n",
    "print(\"Maximum review length: {}\".format(max(sent_lens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
